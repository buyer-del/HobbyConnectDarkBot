# ============================================
#  üîä –ê—É–¥—ñ–æ ‚Üí Google Speech-to-Text (uk-UA)
#  üñºÔ∏è –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è ‚Üí Google Vision API (OCR)
# ============================================

import os
import io
import subprocess
import tempfile
from typing import Optional

from google.cloud import speech_v1 as speech
from google.cloud import vision

# -----------------------------
# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è Google Credentials
# -----------------------------
def _setup_google_credentials() -> None:
    """
    –ù–∞–ª–∞—à—Ç–æ–≤—É—î GOOGLE_APPLICATION_CREDENTIALS –Ω–∞ –æ—Å–Ω–æ–≤—ñ
    –∑–º—ñ–Ω–Ω–æ—ó —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞ GOOGLE_CREDENTIALS_JSON (—è–∫ —É —Ç–≤–æ—î–º—É –∫–æ–¥—ñ).
    """
    google_creds_json = os.environ.get("GOOGLE_CREDENTIALS_JSON")
    if not google_creds_json:
        raise ValueError("‚ùå GOOGLE_CREDENTIALS_JSON –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ —É –∑–º—ñ–Ω–Ω–∏—Ö —Å–µ—Ä–µ–¥–æ–≤–∏—â–∞!")

    creds_path = "/tmp/google_credentials.json"
    with open(creds_path, "w", encoding="utf-8") as f:
        f.write(google_creds_json)

    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = creds_path

_setup_google_credentials()

# –ú–æ–≤–∞ —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è (–∑–∞ –ø–æ—Ç—Ä–µ–±–∏ –º–æ–∂–Ω–∞ –∑–º—ñ–Ω–∏—Ç–∏ —á–µ—Ä–µ–∑ SPEECH_LANGUAGE)
SPEECH_LANGUAGE = os.getenv("SPEECH_LANGUAGE", "uk-UA")


# -----------------------------
# –î–æ–ø–æ–º—ñ–∂–Ω–µ: –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è ‚Üí WAV
# -----------------------------
def _convert_to_wav_16k_mono(input_path: str) -> str:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç—É—î –±—É–¥—å-—è–∫–µ –∞—É–¥—ñ–æ/–≤—ñ–¥–µ–æ –≤ WAV PCM 16-bit, mono, 16000 Hz.
    –í–∏–º–∞–≥–∞—î –Ω–∞—è–≤–Ω–æ—Å—Ç—ñ ffmpeg —É —Å–µ—Ä–µ–¥–æ–≤–∏—â—ñ (–Ω–∞ Render –≤—ñ–Ω –∑–∞–∑–≤–∏—á–∞–π —î).
    –ü–æ–≤–µ—Ä—Ç–∞—î —à–ª—è—Ö –¥–æ —Ç–∏–º—á–∞—Å–æ–≤–æ–≥–æ .wav —Ñ–∞–π–ª—É.
    """
    fd, out_path = tempfile.mkstemp(suffix=".wav")
    os.close(fd)

    # -vn: –≤—ñ–¥–∫–∏–Ω—É—Ç–∏ –≤—ñ–¥–µ–æ (–Ω–∞ –≤–∏–ø–∞–¥–æ–∫ .mp4/.webm)
    # -ac 1: –º–æ–Ω–æ
    # -ar 16000: 16 –∫–ì—Ü
    # -sample_fmt s16: 16-–±—ñ—Ç–Ω–∏–π PCM
    cmd = [
        "ffmpeg",
        "-hide_banner", "-loglevel", "error",
        "-y",
        "-i", input_path,
        "-vn",
        "-ac", "1",
        "-ar", "16000",
        "-sample_fmt", "s16",
        out_path,
    ]
    try:
        subprocess.run(cmd, check=True)
    except subprocess.CalledProcessError as e:
        # –Ø–∫—â–æ ffmpeg –Ω–µ –∑–º—ñ–≥ —Å–∫–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏
        try:
            os.remove(out_path)
        except Exception:
            pass
        raise RuntimeError(f"ffmpeg: –ø–æ–º–∏–ª–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó ({e})")

    return out_path


# -----------------------------
# Google Speech-to-Text
# -----------------------------
def transcribe_audio(input_path: str) -> Optional[str]:
    """
    –†–æ–∑–ø—ñ–∑–Ω–∞—î —É–∫—Ä–∞—ó–Ω—Å—å–∫—É –º–æ–≤—É –∑ –∞—É–¥—ñ–æ —á–µ—Ä–µ–∑ Google Speech-to-Text.
    1) –ó–∞–≤–∂–¥–∏ –∫–æ–Ω–≤–µ—Ä—Ç—É—î —É WAV PCM 16k/16-bit/mono
    2) –í–∏–∫–æ–Ω—É—î —Ä–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è
    3) –ü–æ–≤–µ—Ä—Ç–∞—î —Ç–µ–∫—Å—Ç –∞–±–æ None (—è–∫—â–æ –Ω–µ —Ä–æ–∑–ø—ñ–∑–Ω–∞–Ω–æ/–ø–æ–º–∏–ª–∫–∞)

    –í–ê–ñ–õ–ò–í–û: –ú–∏ –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ None –Ω–∞ –Ω–µ–≤–¥–∞—á—É, –±–æ main.py –ø–æ–∫–∞–∑—É—î –≤–ª–∞—Å–Ω–µ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
    –ø—Ä–æ –ø–æ–º–∏–ª–∫—É ‚Äî —Ü–µ –∑–±–µ—Ä—ñ–≥–∞—î –ø–æ—Ç–æ—á–Ω—É –ø–æ–≤–µ–¥—ñ–Ω–∫—É –±–æ—Ç–∞.
    """
    wav_path = None
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —É WAV
        wav_path = _convert_to_wav_16k_mono(input_path)

        # –ß–∏—Ç–∞—î–º–æ –±—ñ–Ω–∞—Ä–Ω–∏–π –≤–º—ñ—Å—Ç
        with open(wav_path, "rb") as f:
            content = f.read()

        audio = speech.RecognitionAudio(content=content)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=16000,
            language_code=SPEECH_LANGUAGE,
            enable_automatic_punctuation=True,
            # "latest_long" –¥–æ–±—Ä–µ –ø—Ä–∞—Ü—é—î –∑ —Ñ—Ä–∞–∑–∞–º–∏; –∑–∞ –ø–æ—Ç—Ä–µ–±–∏ –º–æ–∂–Ω–∞ "default"
            model="latest_long",
        )

        client = speech.SpeechClient()
        response = client.recognize(config=config, audio=audio)

        # –Ø–∫—â–æ –Ω–µ–º–∞—î —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        if not response.results:
            return None

        parts = []
        for result in response.results:
            if result.alternatives:
                parts.append(result.alternatives[0].transcript)

        text = " ".join(t.strip() for t in parts if t and t.strip())
        return text if text else None

    except Exception as e:
        # –õ–æ–≥—ñ–∫—É –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É —Ä–æ–±–∏—Ç—å main.py,
        # —Ç–æ–º—É —Ç—É—Ç –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ None, —â–æ–± main –ø–æ–∫–∞–∑–∞–≤ —Å–≤–æ—é —Ñ—Ä–∞–∑—É.
        return None

    finally:
        # –ü—Ä–∏–±–∏—Ä–∞—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–π .wav —Ñ–∞–π–ª
        if wav_path and os.path.exists(wav_path):
            try:
                os.remove(wav_path)
            except Exception:
                pass


# -----------------------------
# Google Vision OCR
# -----------------------------
def extract_text_from_image(image_path: str) -> Optional[str]:
    """
    –†–æ–∑–ø—ñ–∑–Ω–∞—î —Ç–µ–∫—Å—Ç —ñ–∑ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —á–µ—Ä–µ–∑ Google Vision API.
    –ü–æ–≤–µ—Ä—Ç–∞—î —Ä—è–¥–æ–∫ –∞–±–æ None.
    """
    try:
        client = vision.ImageAnnotatorClient()

        with open(image_path, "rb") as image_file:
            content = image_file.read()

        image = vision.Image(content=content)
        response = client.text_detection(image=image)

        if response.error.message:
            # –ü—Ä–æ–∫–∏–¥—É—î–º–æ —è–∫ –≤–∏–Ω—è—Ç–æ–∫, —â–æ–± –≤–µ—Ä—Ö–Ω—ñ–π —Ä—ñ–≤–µ–Ω—å –ø–æ–∫–∞–∑–∞–≤ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø—Ä–æ –ø–æ–º–∏–ª–∫—É
            raise RuntimeError(f"Vision API error: {response.error.message}")

        if not response.text_annotations:
            return None

        full_text = (response.text_annotations[0].description or "").strip()
        return full_text or None

    except Exception:
        return None
